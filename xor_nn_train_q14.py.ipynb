{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b69bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, MSE: 0.334530\n",
      "Epoch 1000, MSE: 0.244398\n",
      "Epoch 2000, MSE: 0.205389\n",
      "Epoch 3000, MSE: 0.109894\n",
      "Epoch 4000, MSE: 0.023597\n",
      "Epoch 5000, MSE: 0.010457\n",
      "Epoch 6000, MSE: 0.006410\n",
      "Epoch 7000, MSE: 0.004488\n",
      "Epoch 8000, MSE: 0.003445\n",
      "Epoch 9000, MSE: 0.002802\n",
      "\n",
      "Predictions after training:\n",
      "Input: [0 0], Expected: 0, Predicted: 0.0481, Binary: 0\n",
      "Input: [0 1], Expected: 1, Predicted: 0.9437, Binary: 1\n",
      "Input: [1 0], Expected: 1, Predicted: 0.9567, Binary: 1\n",
      "Input: [1 1], Expected: 0, Predicted: 0.0430, Binary: 0\n",
      "\n",
      "VHDL constants for Q14 weights/biases:\n",
      "constant W10_0 : signed(31 downto 0) := to_signed(90628, 32);\n",
      "constant W10_1 : signed(31 downto 0) := to_signed(-91933, 32);\n",
      "constant B10 : signed(31 downto 0) := to_signed(-50260, 32);\n",
      "constant W11_0 : signed(31 downto 0) := to_signed(83372, 32);\n",
      "constant W11_1 : signed(31 downto 0) := to_signed(-80423, 32);\n",
      "constant B11 : signed(31 downto 0) := to_signed(39347, 32);\n",
      "constant W20_0 : signed(31 downto 0) := to_signed(124845, 32);\n",
      "constant W20_1 : signed(31 downto 0) := to_signed(-119564, 32);\n",
      "constant B20 : signed(31 downto 0) := to_signed(55170, 32);\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -------------------------------\n",
    "# Q14 conversion functions\n",
    "# -------------------------------\n",
    "def float_to_q14(value):\n",
    "    \"\"\"Convert float to Q14 integer\"\"\"\n",
    "    return int(np.round(value * (2**14)))\n",
    "\n",
    "def q14_to_float(q14_value):\n",
    "    \"\"\"Convert Q14 integer back to float\"\"\"\n",
    "    return q14_value / (2**14)\n",
    "\n",
    "# -------------------------------\n",
    "# Neuron class with Q14 quantization\n",
    "# -------------------------------\n",
    "class Neuron:\n",
    "    def __init__(self, num_inputs):\n",
    "        self.weights = np.random.uniform(-1, 1, size=num_inputs)\n",
    "        self.bias = np.random.uniform(-1, 1)\n",
    "\n",
    "    def activate(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.output = self.sigmoid(np.dot(inputs, self.weights) + self.bias)\n",
    "        return self.output\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    def sigmoid_derivative(self):\n",
    "        return self.output * (1 - self.output)\n",
    "\n",
    "    def update_weights(self, delta, learning_rate):\n",
    "        # Standard gradient update\n",
    "        self.weights += learning_rate * delta * self.inputs\n",
    "        self.bias += learning_rate * delta\n",
    "\n",
    "        # Quantize weights and bias to Q14 after each update\n",
    "        self.weights = np.array([q14_to_float(float_to_q14(w)) for w in self.weights])\n",
    "        self.bias = q14_to_float(float_to_q14(self.bias))\n",
    "\n",
    "# -------------------------------\n",
    "# Layer class\n",
    "# -------------------------------\n",
    "class Layer:\n",
    "    def __init__(self, num_neurons, num_inputs_per_neuron):\n",
    "        self.neurons = [Neuron(num_inputs_per_neuron) for _ in range(num_neurons)]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return np.array([neuron.activate(inputs) for neuron in self.neurons])\n",
    "\n",
    "    def backward(self, errors, learning_rate):\n",
    "        deltas = []\n",
    "        for i, neuron in enumerate(self.neurons):\n",
    "            # Computes delta for each neuron: error Ã— sigmoid derivative.\n",
    "            delta = errors[i] * neuron.sigmoid_derivative()\n",
    "            neuron.update_weights(delta, learning_rate)\n",
    "            deltas.append(delta)\n",
    "        return np.dot(np.array([neuron.weights for neuron in self.neurons]).T, deltas)\n",
    "\n",
    "# -------------------------------\n",
    "# Neural Network class\n",
    "# -------------------------------\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, learning_rate=0.1, epochs=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.layers = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.layers.append(Layer(layers[i+1], layers[i]))\n",
    "\n",
    "    def train(self, inputs, outputs):\n",
    "        for epoch in range(self.epochs):\n",
    "            total_error = 0\n",
    "            for x, y in zip(inputs, outputs):\n",
    "                activations = [x]\n",
    "                for layer in self.layers:\n",
    "                    #current layer\n",
    "                    activations.append(layer.forward(activations[-1]))\n",
    "\n",
    "                output_errors = y - activations[-1]\n",
    "                total_error += np.sum(output_errors ** 2)\n",
    "\n",
    "                errors = output_errors\n",
    "                for i in reversed(range(len(self.layers))):\n",
    "                    errors = self.layers[i].backward(errors, self.learning_rate)\n",
    "\n",
    "            if epoch % 1000 == 0:\n",
    "                mse = total_error / len(inputs)\n",
    "                print(f'Epoch {epoch}, MSE: {mse:.6f}')\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        activations = inputs\n",
    "        for layer in self.layers:\n",
    "            activations = layer.forward(activations)\n",
    "        return activations\n",
    "\n",
    "# -------------------------------\n",
    "# Train XOR network\n",
    "# -------------------------------\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "nn = NeuralNetwork([2, 2, 1], learning_rate=0.1, epochs=10000)\n",
    "nn.train(inputs, outputs)\n",
    "\n",
    "# -------------------------------\n",
    "# Print predictions\n",
    "# -------------------------------\n",
    "print(\"\\nPredictions after training:\")\n",
    "for x, y in zip(inputs, outputs):\n",
    "    pred = nn.predict(x)\n",
    "    print(f\"Input: {x}, Expected: {y[0]}, Predicted: {pred[0]:.4f}, Binary: {int(pred[0] > 0.5)}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Export VHDL constants (Q14)\n",
    "# -------------------------------\n",
    "print(\"\\nVHDL constants for Q14 weights/biases:\")\n",
    "for l_idx, layer in enumerate(nn.layers):\n",
    "    for n_idx, neuron in enumerate(layer.neurons):\n",
    "        # Weights\n",
    "        for w_idx, w in enumerate(neuron.weights):\n",
    "            q14_val = float_to_q14(w)\n",
    "            print(f\"constant W{l_idx+1}{n_idx}_{w_idx} : signed(31 downto 0) := to_signed({q14_val}, 32);\")\n",
    "        # Bias\n",
    "        q14_bias = float_to_q14(neuron.bias)\n",
    "        print(f\"constant B{l_idx+1}{n_idx} : signed(31 downto 0) := to_signed({q14_bias}, 32);\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
